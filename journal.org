# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:       Journal
#+AUTHOR:      Hoël Jalmin
#+LANGUAGE:    en
#+SEQ_TODO: TODO(t!) STARTED(s!) INTERRUPTED(i!) DONE(d!)

* Introduction
This file is the report for my internship, about automating
calculation kernels' modellings. I'll explain more about this later on.

* 2019
** 2019-04 april
*** 2019-04-30 monday
**** DONE Read [[https://hal.inria.fr/hal-02096571/document ][Faithful and Efficient Simulation of High Performance Linpack]] :PAPER:
:LOGBOOK:  
- State "DONE"       from "STARTED"    [2019-05-02 thursday 16:53]
:END:      
***** Introduction
With a power consumption of several MW per hour on a TOP500 machine,
running applications on supercomputers at scale solely to optimize
their performance is extremely expensive. Likewise, High-Performance
Linpack (HPL), the benchmark used to ran supercomputers in the TOP500,
requires a careful tuning of many parameters (problem size, grid
arrangement, granularity, collective operation algorithms, etc.) and
supports exploration of the most common and fundamental performance
issues and their solutions. In this article, we explain how we both
extended the SimGrid's SMPI simulator and slightly modified the
open source version of HPL to allow a fast emulation on a single
commodity server at the scale of a supercomputer. We explain how to
model the different components (network, BLAS, ...) and show that a
careful modeling of both spatial and temporal node variability allows us
to obtain predictions within a few percents of real experiments.

***** Notes 
The paper explains how to extend the Simgrid simulator to simulate the
HPL benchmark and get the rough performance of it, as it is quite
representative of usual performance issues, without actually running
it. The simulation reduces considerably memory consumption compared to
a normal run of HPL, so it can be ran on a smaller cluster with less
time. Other simulation models for HPL already existed, but were quite
inaccurate as they did not take all the parameters in account.

****** About HPL
HPL is a parallel implementation of a benchmark which measures how
fast a computer can solve a system of linear equations. HPL uses the
BLAS libraries to make matrix operations such as multiplication (using
dgemm). The sequential complexity depends on the matrix size: 
2/3N³ + 2N² + O(N), but the calculation time cannot be determined
without running HPL or a simulation of it (it depends on network
capacity and a lot of parameters). Even while running HPL there's a
difference between the theoretical peak performance and the actual one
reached depending on how MPI communications are done.


****** About SimGrid and MPI simulation
There are two approaches to MPI simulation: offline and online. The
first one gives a previously obtained trace of the application to a
simulator, which makes predictions depending on the performance
models. The issue is that a first run is necessary to get the trace,
which is only valid at the moment of the run, since it depicts a
precise behavior. Thus, predictions are extrapolated which can be an
issue if the execution is non deterministic. This simulation type is
not proper for HPL, whereas online simulation (used by SimGrid) means
the simulator directs the execution; it decides which process to run
at which time. SimGrid provides accurate performance models for
application with heavy network use, as it considers network topology
and heterogeneity. SMPI, based on SimGrid, runs MPI ranks on mutually
exclusive threads, so whenever a thread enters an MPI call, SMPI moves
its clock ahead of the time spent computing since the last MPI call.


****** DONE About how to emulate HPL
:LOGBOOK:  
- State "DONE"       from "STARTED"    [2019-05-02 thursday 10:51]
- State "STARTED"    from "TODO"       [2019-05-02 thursday 09:39]
:END:      
Most of the calculation time of HPL is spent in the dgemm and dtrsm
(A.x = b equations) kernels, so replacing these two by models greatly
reduces simulation time: it was only be necessary to make a SMPI call
when one of these kernels were used (this makes results incorrect). 
Likewise, other functions were replaced since they used incorrect data
because of dgemm and dstrsm. Initialization of pseudo-random matrices
and correctness verification were also skipped, changing the idamax
function to return random values, making the simulation deterministic.

Memory consumption was scaled down by sharing the input matrix A
between all MPI processes and indicating that its data can be
overwritten. For the panel matrix, containing matrix indexes, data
corruption cannot be risked so a partial shared malloc was introduced,
to only share the range of values that doesn't have matrix indexes. 
The number of allocations and page faults was also greatly reduced by
reusing the allocated panels instead of getting more of them. Also, a
lot of calls to memcopy were avoided by making SMPI aware of which
memory areas were private or not. Calls to mmap (used to remap the
data segment to the private copy of the MPI rank when context
switching) were also avoided by loading several times the data segment
into memory. Finally, huge pages were used so the page table wouldn't
be too large.

All of these changes allowed a reduced complexity by removing the
O(N³) part.


****** DONE About the chosen models for kernels and communications
:LOGBOOK:  
- State "DONE"       from "STARTED"    [2019-05-02 thursday 16:05]
- State "STARTED"    from "TODO"       [2019-05-02 thursday 10:51]
:END:      
Several modeling notations were chosen. M-0 means the duration is
roughly constant and independant of the input parameters. M-1 means
the performance depends on a combination of the parameters. M-2
is used when a polynomial model is required (for complex behavior). 
M_H means the platform has spatial variability and modeling should
be done for each host, and M' is used when the duration is linear for
specific parameters values. The same was done for the noise: N-0 means
no noise, N-1 means the noise has a normal distribution, N-2 means the
noise has to be modelised by a polynomial function. N_H means noise
estimations are made per-host and N' is when the noise is modelised by
several normal distributions.

Communications between MPI nodes are mostly linear in message size but
vary depending on the protocol used. The chosen model was a M'-1
(linear within each host but discontinuous) N'-1 (complex distribution
of linear noise) model, with its paramaters estimated by pytree: the
message size range and the 2-4 modes of the normal distribution mixture.

For dgemm, a polynomial model (M_H-2) was required because of the spatial
variability: depending on the value of M*N*K (so on the matrix size),
some durations will be higher than others regardless of the node used
(which means dgemm doesn't have a linear behavior). There is also some
temporal variability, modelized here by a random call. For other BLAS
and HPL kernels, a linear model M-1 is close enough to reality; but the
noise needs to follow a N-2 model because the variability it provides
increases with the value of the parameters (which indicates a
polynomial model).


****** DONE The simulation at scale
:LOGBOOK:  
- State "DONE"       from "STARTED"    [2019-05-02 thursday 16:53]
- State "STARTED"    from "TODO"       [2019-05-02 thursday 16:20]
:END:      
After working on these optimizations, an emulation was done at scale
using the Dahu cluster, with a high number of iterations, complex
communication patterns and more MPI processes than usual. The
emulation was stopped after five iterations, to compare to real runs:
the communication durations were a bit too optimistic, and it was
noted that using a complex model makes more realistic traces. Several
simulations were then done to figure out which model would be more
accurate, and the models that are the closest to reality are: M-1 N-2
for the kernels, M_H-2 N_H-2 for dgemm and M'-1 N-0 for the network. 
Adding a linear noise for the network doesn't have any visible effect.

This was compared to the run made on the Stampede cluster. Considering
the input parameters for this run and the result, an optimistic model
(M'-1 N-0) was chosen for the dgemm and dtrsm functions, as well as
for the MPI communications, while ignoring the other functions. 
Although usually the simulations are within of few percent of reality,
the performance of this one was much lower than the performance of the
Stamepde run, which used a modified version of HPL and different
parameters than the ones printed by HPL. It was also found that the
communications had been optimized for the run, which explains the
difference between the simulation and the reality.

*** 2019-04-30 tuesday
**** Installed Emacs and Org-mode and all required dependencies.
Followed the given MOOC to understand how Org-mode functions, and how
to take efficient notes. Learned the basics of org-mode, and of the
keyboard shortcuts introduced by the provided emacs initialization.

**** Began writing the journal
** 2019-05 may
*** 2019-05-02 thursday
**** Attended the keynote speech about contrasting artifical and human intelligence by Jean-Louis Dessales :SEMINAR:
***** Introduction
Some artificial intelligence techniques were recently able to scale
up, provoking what many consider as a technical revolution. However,
the type of AI that proved so successful in the past decade relies on
the exploitation of massive data, and is limited to narrow domains of
expertise. By contrast, human intelligence is very efficient at making
broad inferences from limited evidence. I will highlight a few
qualitative differences between artificial intelligence and human
intelligence. These differences are mainly due to a small set of
cognitive operations, such as contrast or simplicity detection, that
human beings perform on the fly. I will also suggest that attempting
to bridge the gap between these two forms of intelligence might be the
best way to improve artificial systems in the future.

***** Notes
- It is often said that artificial intelligence will eventually replace
 mankind, but Jean-Louis Dessales clearly doesn't think so. It is
 foolish for him to believe there is a loss function that can be
 applied for everything.

- There are specific characteristics of artifical intelligence that
  makes them too different from human beings to be able to solve every
  problem humans are able to.
 
  + For instance, neuronal networks work best when they can analyse a
    lot of data, to then be able to recognize it. This can work for
    fields such as image recognition, but not for particular fields
    such as criminal investigation where every case is different and
    the possible similarity between cases is only an average and
    cannot be exact. Also artificial intelligence work without biases,
    unlike human beings.

  + Artificial intelligence function in an isotropic way, they can
    learn how to recognize language even if the order of the words in
    the sentences is mixed up; whereas this will just confuse human
    beings. However, even though artificial intelligences recognize
    language they do not understand it, and if they try to speak they
    often make no sense because they look at semantics similarity and
    not semantics itself. Any idoms are lost to them, because they
    will not recognize it.

  + Neuronal networks are also unable to recognize a pattern if they
    were not introduced to it, and have very narrow expertise. For
    example, if given a sequence of numbers, they will be unable to
    find the next ones (ex: 1223334444). As they work with recognition
    instead of understanding, trying to broaden their expertise will
    sometimes fail. For example a neuronal network made to recognize
    skin cancer cannot recognize psoriasis, and trying to change it
    will reduce their ability to see skin cancer.

- When attempting to solve problems, human beings look for simplicity:
  the least complexity is the best. How humans see complexity and
  unexpectedness is by a difference between what they expect and what
  they see.

  + Unexpectedness can be defined as a complexity drop between what was
    expected and what happened. For example, seeing a "simple" (well
    known) person in a "complex" (rarely visited) place is unexpected,
    because of the difference in complexity.

- Because of the way humans learn by making connections (for example
  when learning a new word the context is immediately connected with
  it; if a child hears their parent talk about "chopping the fish"
  they are able to connect it to the place they heard it, to the food
  associated with it...), artificial intelligence cannot replace
  humans in the sense that this process of learning is completely
  foreign to them. They do not process the relations between objects,
  they focus on pattern recognition.
*** 2019-05-03 friday
**** INTERRUPTED Read [[http://xcelab.net/rm/statistical-rethinking ][A Bayesian Course with examples in R and Stan]] by Richard McElreath :PAPER:STAN:
:LOGBOOK:  
- State "INTERRUPTED" from "STARTED"    [2019-05-06 lun. 18:52]
:END:      
***** About models
- Models are like golems, powerful but easy to misuse.
- Use of models is wide spread and necessary but giving too many
  models is confusing, you need to find the right one. statistical
  tools are not diverse enough.
- Falsifying null hypothesis isn't enough. it would be more logical to
  falsify an explanatory model because falsifying a null model bring
  very little knowledge.
- Hypotheses correspond to several process models, and statistical
  models correspond to several process models
- Bayesian statistics are able to process small samples and don't need
  a prior hypothesis to confirm or reject. In bayesian statistics,
  probabilities are interpreted as uncertainty, models' parameters are
  modelled by probability laws and parameters are
  approximated by execution.
- On a des observations/déductions prior, qui nous aident à aiguiller
  l'analyse

***** About priors, likelihood and posteriors
- Small worlds are the logical worlds of the models. There are no
  surprises, and it's possible to verify the models's logic and if it
  works properly. Whereas in large worlds there might be unpredicted
  events, and the models never completely encompass large worlds.
- Bayesian analysis are garden of forking data: multiple paths exist,
  with each one branching more possibilities as we explore the
  paths. By getting more observations, we prune some path so to keep
  only the ones consistant to our data.
- Prior information can help us find the plausability of each path.
- The plausability of x knowing y is proportional to the number of
  ways x can produce y * the prior plausability of x.
- Models are built on the way, updated each time we get data that
  confirms or denies it's prior assumptions. They learn with each set
  of plausabilities.
- A model is a mix of a likelihood, which represents the plausability
  of the data given a fixed value as parameter, several parameters and
  a prior (the plausability of each value of the parameters).
- Bayes theorem: P(A∩B) = P(A|B)Pr(B) = P(B|A)Pr(A) 
  aka Posterior = Likelihood*Prior / Average Likelihood
  Pr(A|B) = Pr(B|A)*Pr(A)/(Pr(B|A)*Pr(A))+(Pr(B|A¯)*Pr(A¯))
- Grid approximation uses a finite grid of parameters values and
  scales poorly. When we have several parameters, we use a quadratic
  approximation (to describe the normal shape of the posterior).

**** INTERRUPTED [[https://www.youtube.com/watch?v=BWEtS3HuU5A&list=PLDcUM9US4XdM9_N6XUUFrhghGJ4K25bFc&index=10 ][Listened to several lectures by Richard McElreath]] :VIDEO:STAN:
:LOGBOOK:  
- State "INTERRUPTED" from "STARTED"    [2019-05-06 lun. 18:52]
:END:      
These lectures are available on his youtube channel, and explain in
more detail what his book is about. Skipped to the Markov Chain Monte
Carlo part.

*** 2019-05-06 monday
**** Continued to read the book, notes in last friday's section
**** Talked to Tom about a simple Stan example and notebooks
**** Started to use Stan with simple cases, following Tom's example :STAN:R:

We start by generating some data following a relatively straight line,
with some noise.

#+begin_src R :results output :session *R* :exports both
generate_dataset=function(intercept, coefficient, N, min_x=0, max_x=100, sigma=1){
    x = sample(min_x:max_x,N,replace=T) 
    y = coefficient * x + intercept + rnorm(N,sd=sigma)
    df = data.frame(x=x,y=y)
    return(df)
}
df=generate_dataset(50, -2, 500, sigma=15)
head(df)
#+end_src

#+RESULTS:
:  
:    x          y
: 1 57  -48.30702
: 2 52  -43.57117
: 3 40  -31.34614
: 4 86 -118.25581
: 5 85 -104.06467
: 6 34  -17.04022

#+begin_src R :results output graphics :file ./images/figure.png :exports both :width 600 :height 400 :session *R* 
library(ggplot2)
ggplot(df, aes(x=x, y=y))+geom_point(alpha=0.3)
#+end_src

#+RESULTS:
[[file:./images/figure.png]]

Then, we define a stan model.

#+begin_src R :results output :session *R* :exports both
library(rstan)

modelString = "data { // the observations
    int<lower=1> N; // number of points
    vector[N] x;
    vector[N] y;
}
parameters { // what we want to find
    real intercept;
    real coefficient;
    real<lower=0> sigma; // indication: sigma cannot be negative
} 
model {
    // We define our priors
    intercept   ~ normal(0, 10); // We know that all the parameters follow a normal distribution
    coefficient ~ normal(0, 10);
    sigma       ~ normal(0, 10);

    // Then, our likelihood function
    y ~ normal(coefficient*x + intercept, sigma);
}
"
sm = stan_model(model_code = modelString)

#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
data = list(N=nrow(df),x=df$x,y=df$y)
fit = sampling(sm,data=data, iter=500, chains=8)
print(fit)
#+end_src

#+RESULTS:
#+begin_example

Inference for Stan model: ea4b5a288cf5f1d87215860103a9026e.
8 chains, each with iter=500; warmup=250; thin=1; 
post-warmup draws per chain=250, total post-warmup draws=2000.

                mean se_mean   sd     2.5%      25%      50%      75%    97.5%
intercept      48.28    0.04 1.31    45.72    47.40    48.29    49.15    50.97
coefficient    -1.97    0.00 0.02    -2.01    -1.98    -1.97    -1.95    -1.92
sigma          14.48    0.01 0.46    13.63    14.16    14.46    14.79    15.41
lp__        -1596.29    0.04 1.23 -1599.49 -1596.88 -1595.98 -1595.37 -1594.87
            n_eff Rhat
intercept     969 1.00
coefficient  1054 1.00
sigma        1029 1.01
lp__          800 1.00

Samples were drawn using NUTS(diag_e) at Mon May  6 19:07:45 2019.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
#+end_example

#+begin_src R :results output graphics :file ./images/stan_plot.png :exports both :width 600 :height 400 :session *R* 
plot(fit)
#+end_src

#+RESULTS:
[[file:./images/stan_plot.png]]

#+begin_src R :results output graphics :file ./images/stan_trace.png :exports both :width 600 :height 400 :session *R* 
traceplot(fit)
#+end_src

#+RESULTS:
[[file:./images/stan_trace.png]]


