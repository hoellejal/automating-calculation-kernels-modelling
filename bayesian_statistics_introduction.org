# -*- coding: utf-8 -*-
# -*- mode: org -*-
#+Title:  Modeling calculation kernels
#+Author: HoÃ«l Jalmin \newline Tutored by Arnaud Legrand and Tom Cornebize
#+DATE: The 21th of June, 2019
#+LANGUAGE: en
#+STARTUP: beamer indent inlineimages logdrawer
#+TAGS: noexport(n)

#+PROPERTY: header-args  :session :eval never-export :exports both
#+DRAWERS: latex_headers

:latex_headers:
#+LaTeX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [10pt,presentation,xcolor={usenames,dvipsnames,svgnames,table}]
#+OPTIONS:   H:2 num:t toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+LATEX_COMPILER: lualatex
#+LATEX_HEADER: \usedescriptionitemofwidthas{bl}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{figlatex}
#+LATEX_HEADER: \usepackage[french]{babel}
#+LATEX_HEADER: %\usepackage{DejaVuSansMono}
#+LATEX_HEADER: \usepackage{ifthen,amsmath,amstext,gensymb,amssymb}
#+LATEX_HEADER: \usepackage{boxedminipage,xspace,multicol}
#+LATEX_HEADER: %%%%%%%%% Begin of Beamer Layout %%%%%%%%%%%%%
#+LATEX_HEADER: \ProcessOptionsBeamer
#+LATEX_HEADER: \usetheme[numbering=fraction,titleformat=smallcaps,progressbar=frametitle]{metropolis}
#+LATEX_HEADER: \usepackage{fontawesome}
#+LATEX_HEADER: \usecolortheme[named=BrickRed]{structure}
#+LATEX_HEADER: %%%%%%%%% End of Beamer Layout %%%%%%%%%%%%%
#+LATEX_HEADER: \usepackage{verbments}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{url} \urlstyle{sf}
#+LATEX_HEADER: \let\alert=\structure % to make sure the org * * works of tools
#+LATEX_HEADER: %\let\tmptableofcontents=\tableofcontents
#+LATEX_HEADER: %\def\tableofcontents{}
#+LATEX_HEADER:  \usepackage[normalem]{ulem}
#+LATEX_HEADER:  \usepackage{color,soul}
#+LATEX_HEADER:  \definecolor{lightorange}{rgb}{1,.9,.7}
#+LATEX_HEADER:  \sethlcolor{lightorange}
#+LATEX_HEADER:  \definecolor{lightgreen}{rgb}{.7,.9,.7}
#+LATEX_HEADER:  \let\hrefold=\href
#+LATEX_HEADER:  \renewcommand{\href}[2]{\hrefold{#1}{\SoulColor{lightorange}\hl{#2}}}
#+LATEX_HEADER: % \renewcommand{\uline}[1]{\SoulColor{lightorange}\hl{#1}}
#+LATEX_HEADER: \renewcommand{\emph}[1]{\SoulColor{lightorange}\hl{#1}}
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \newcommand\SoulColor[1]{%
#+LATEX_HEADER:   \sethlcolor{#1}%
#+LATEX_HEADER:   \let\set@color\beamerorig@set@color%
#+LATEX_HEADER:   \let\reset@color\beamerorig@reset@color}
#+LATEX_HEADER: \makeatother
#+LATEX_HEADER: \let\oldtexttt=\texttt
#+LATEX_HEADER: % \renewcommand\texttt[1]{\SoulColor{lightgreen}\hl{\tt#1}}
#+LATEX_HEADER: % \renewcommand\alert[1]{\SoulColor{lightgreen}\hl{#1}}
#+LATEX_HEADER: % \AtBeginSection{\begin{frame}{Outline}\tableofcontents\end{frame}}
#+LATEX_HEADER: \graphicspath{{fig/}}
#+LATEX_HEADER: \usepackage{tikzsymbols}
#+LATEX_HEADER: \def\smiley{\Smiley[1][green!80!white]}
#+LATEX_HEADER: \def\frowny{\Sadey[1][red!80!white]}
#+LATEX_HEADER: \def\winkey{\Winkey[1][yellow]}

#+BEGIN_EXPORT latex
  \newcommand{\myfbox}[2][gray!20]{\bgroup\scalebox{.7}{\colorbox{#1}{{\vphantom{pS}#2}}}\egroup} % \fbox
  %\def\myfbox#1{#1} % \fbox
  \def\HPC{\myfbox[gray!40]{HPC}}
  \def\NET{\myfbox[gray!40]{Network}}
  \def\SG{\myfbox[gray!40]{Smart Grids}}
  \def\ECO{\myfbox[gray!40]{Economics}}
  \def\PRIV{\myfbox[gray!40]{Privacy}}
  \def\TRACING{\myfbox[red!20]{Tracing}}
  \def\SIM{\myfbox[green!20]{Simulation}}
  \def\VIZ{\myfbox[red!40]{Visualization}}
  \def\MODELING{\myfbox[green!40]{Stochastic Models}}
  \def\OPT{\myfbox[blue!20]{Optimization}}
  \def\GT{\myfbox[blue!40]{Game Theory}}
#+END_EXPORT


#+BEGIN_EXPORT latex
\def\changefont#1{%
  \setbeamertemplate{itemize/enumerate body begin}{#1}
  \setbeamertemplate{itemize/enumerate subbody begin}{#1}
  #1}
\makeatletter
\newcommand{\verbatimfont}[1]{\renewcommand{\verbatim@font}{\ttfamily#1}}
\makeatother
\verbatimfont{\scriptsize}%small
\let\endmintedbak=\endminted
\def\endminted{\endmintedbak\vspace{-1cm}}
#+END_EXPORT

#+BEGIN_EXPORT latex
\newcommand{\Norm}{\ensuremath{\mathcal{N}}\xspace}
\newcommand{\Unif}{\ensuremath{\mathcal{U}}\xspace}
\newcommand{\Triang}{\ensuremath{\mathcal{T}}\xspace}
\newcommand{\Exp}{\ensuremath{\mathcal{E}}\xspace}
\newcommand{\Bernouilli}{\ensuremath{\mathcal{B}}\xspace}
\newcommand{\Like}{\ensuremath{\mathcal{L}}\xspace}
\newcommand{\Model}{\ensuremath{\mathcal{M}}\xspace}
\newcommand{\E}{\ensuremath{\mathbb{E}}\xspace}
\def\T{\ensuremath{\theta}\xspace}
\def\Th{\ensuremath{\hat{\theta}}\xspace}
\def\Tt{\ensuremath{\tilde{\theta}}\xspace}
\def\Y{\ensuremath{y}\xspace}
\def\Yh{\ensuremath{\hat{y}}\xspace}
\def\Yt{\ensuremath{\tilde{y}}\xspace}
\let\epsilon=\varepsilon
\let\leq=\leqslant
\let\geq=\geqslant
#+END_EXPORT
:end:

# https://cran.r-project.org/web/packages/plot3D/vignettes/plot3D.pdf
# http://htmlpreview.github.io/?https://github.com/AckerDWM/gg3D/blob/master/gg3D-vignette.html

# http://bechtel.colorado.edu/~bracken/tutorials/stan/stan-tutorial.pdf
# http://jakewestfall.org/misc/SorensenEtAl.pdf
# https://github.com/AllenDowney/BayesMadeSimple

# https://github.com/bob-carpenter/prob-stats

#+BEGIN_EXPORT latex
#+END_EXPORT

** Context
With the current need for high performance computing, and the hardware
complexity:
- How to predict the duration of calculations?
- How to check if the performance is normal?

*** For this talk:
1. Brief presentation of the context
2. Introduction to Bayesian sampling
3. Examples of application

** Background on HPC and Polaris research
*** Modern context
  - HPC systems use thousands of nodes, multiple levels of cache, hyperthreading, etc -> makes it difficult to predict performance
  - Some functions are used everywhere, and called thousands of times

*** Polaris research
  - Simulating HPL on smaller supercomputers to optimize it at a
    lesser cost
  - Elaborated complex models but needed to evaluate and confirm the models

** HPL simulation
*** Examples
  - The blas library is used by thousands of programs and constitutes
    most of HPL calculations.
  - Performance variability is also caused by network communications
  - Needs to check the models with bayesian sampling.

* Bayesian Statistics
** Bayes model
- Model :: Let's say $y \sim \Norm(\mu,\sigma)$
  - *$\mu$*: Model *parameters*
  - *$y$*: Dependent *data* (posterior)
  - *$\sigma$*: Independent data (prior)
  We observe some data and need to find model parameters

*** The vocabulary
  - *Posterior*: The distribution of the parameters
  - *Likelihood*: A function of the parameters, the model
  - *Prior*: Existing knowledge of the system, guesses on the parameters
    values
$\boxed{\underbrace{p(\mu|y,\sigma)}_{\text{\alert{Posterior}}} \propto \underbrace{p(y|\mu,\sigma)}_{\text{\alert{Likelihood}}}\underbrace{p(\mu,\sigma)}_{\text{\alert{Prior}}}}$
  assuming $y \sim \Model(\mu,\sigma)$

** TODO Bayesian Sampling

* A Bayesian Sampler, Stan
** With a simple example
#+begin_src R :results output :session *R* :exports none
generate_dataset=function(intercept, coefficient, N, min_x=0, max_x=100, sigma=1){
    x = sample(min_x:max_x,N,replace=T) 
    y = coefficient * x + intercept + rnorm(N,sd=sigma)
    df = data.frame(x=x,y=y)
    return(df)
}
df=generate_dataset(50, -2, 500, sigma=15)
#+end_src

[[file:./images/ex1_figure.png]]
Using this data, we'll try to find the parameters that were used to
generate it.

** The Stan model
#+begin_example
library(rstan)

modelString = "data { // the observations
    int<lower=1> N; // number of points
    vector[N] x;
    vector[N] y;
}
parameters { // what we want to find
    real intercept;
    real coefficient;
    real<lower=0> sigma; // indication: sigma cannot be negative
} 
model {
    // We define our priors
    intercept   ~ normal(0, 10); // We know that all the parameters follow a normal distribution
    coefficient ~ normal(0, 10);
    sigma       ~ normal(0, 10);

    // Then, our likelihood function
    y ~ normal(coefficient*x + intercept, sigma);
}
"
sm = stan_model(model_code = modelString)
#+end_example

#+begin_src R :results output :session *R* :exports none
library(rstan)

modelString = "data { // the observations
    int<lower=1> N; // number of points
    vector[N] x;
    vector[N] y;
}
parameters { // what we want to find
    real intercept;
    real coefficient;
    real<lower=0> sigma; // indication: sigma cannot be negative
} 
model {
    // We define our priors
    intercept   ~ normal(0, 10); // We know that all the parameters follow a normal distribution
    coefficient ~ normal(0, 10);
    sigma       ~ normal(0, 10);

    // Then, our likelihood function
    y ~ normal(coefficient*x + intercept, sigma);
}
"
sm = stan_model(model_code = modelString)
#+end_src

** Making the fit and checking the results
#+begin_src R :results output :session *R* :exports both
data = list(N=nrow(df),x=df$x,y=df$y)
fit = sampling(sm,data=data, iter=500, chains=8)
#+end_src

#+begin_src R :results output :session *R* :exports both
print(fit)
#+end_src

#+RESULTS:
#+begin_example
Inference for Stan model: ea4b5a288cf5f1d87215860103a9026e.
8 chains, each with iter=500; warmup=250; thin=1; 
post-warmup draws per chain=250, total post-warmup draws=2000.

                mean se_mean   sd     2.5%      25%      50%      75%    97.5%
intercept      49.86    0.04 1.36    47.14    48.94    49.87    50.82    52.40
coefficient    -2.00    0.00 0.02    -2.04    -2.01    -2.00    -1.98    -1.95
sigma          15.03    0.01 0.47    14.18    14.70    15.02    15.35    15.99
lp__        -1615.90    0.04 1.12 -1618.80 -1616.45 -1615.62 -1615.05 -1614.58
            n_eff Rhat
intercept    1070 1.00
coefficient  1042 1.00
sigma        1042 1.01
lp__          871 1.00

Samples were drawn using NUTS(diag_e) at Wed Jun 19 17:07:18 2019.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
#+end_example

** Checking the convergence

#+begin_src R :results output graphics :file ./images/ex1_stan_trace.png :exports both :session *R* 
stan_trace(fit)
#+end_src

#+RESULTS:
[[file:./images/ex1_stan_trace.png]]

** TODO Generating new data
** TODO A polynomial model with specific noise 
** TODO A model depending on the host
** TODO A hierarchical model
** TODO The importance of the priors
** TODO Posterior visualisation
** The follow up

- Possibilities ::
  - Modeling other calculation kernels
  - Modeling the network communications
  - Parsing and converting Stan code to C, to generate new data more efficiently
  - Anomaly detection
